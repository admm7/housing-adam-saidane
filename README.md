#  Housing Price Prediction with Kafka and Flask

Ce projet implÃ©mente un systÃ¨me de prÃ©diction de prix de maisons en utilisant **Kafka**, **Flask**, et **PostgreSQL**. L'architecture repose sur une communication entre plusieurs services DockerisÃ©s :

1. Un **Producer Kafka** qui envoie des messages contenant des donnÃ©es sur les maisons.
2. Un **Consumer Kafka** qui Ã©coute ces messages, les stocke dans une base de donnÃ©es et envoie une requÃªte Ã  l'API de prÃ©diction.
3. Une **API Flask (housing-api)** qui stocke les maisons dans une base PostgreSQL.
4. Une **API Flask de prÃ©diction (housing-model)** qui utilise un modÃ¨le de Machine Learning pour estimer le prix d'une maison.

---

##  Structure du projet

```
 tp-housing-adam-saidane
â”‚â”€â”€ housing-api/                     # API Flask pour gÃ©rer les donnÃ©es de logement
â”‚   â”‚â”€â”€ app.py                        # Code principal de l'API Flask
â”‚   â”‚â”€â”€ config.py                     # Configuration de la base de donnÃ©es
â”‚   â”‚â”€â”€ data.json                      # DonnÃ©es JSON (si applicable)
â”‚   â”‚â”€â”€ dockerfile                     # Dockerfile pour l'API
â”‚   â”‚â”€â”€ requirements.txt               # DÃ©pendances Python pour l'API
â”‚
â”‚â”€â”€ housing-consumer/                  # Consumer Kafka qui rÃ©cupÃ¨re et envoie les donnÃ©es
â”‚   â”‚â”€â”€ consumer.py                    # Code du consommateur Kafka
â”‚   â”‚â”€â”€ dockerfile                     # Dockerfile pour le consumer
â”‚   â”‚â”€â”€ requirements.txt               # DÃ©pendances pour le consumer
â”‚
â”‚â”€â”€ housing-model/                      # API Flask pour les prÃ©dictions
â”‚   â”‚â”€â”€ app.py                          # Code principal de l'API de prÃ©diction
â”‚   â”‚â”€â”€ best_model.pkl                  # ModÃ¨le entraÃ®nÃ© sauvegardÃ©
â”‚   â”‚â”€â”€ dockerfile                       # Dockerfile pour le modÃ¨le
â”‚   â”‚â”€â”€ requirements.txt                 # DÃ©pendances du modÃ¨le
â”‚   â”‚â”€â”€ load_data.py                     # Script pour charger les donnÃ©es
â”‚   â”‚â”€â”€ housing.csv                      # Dataset original
â”‚   â”‚â”€â”€ housing_cleaned.csv              # Dataset nettoyÃ©
â”‚   â”‚â”€â”€ Etape 3 housing-model/           # Dossier pour l'analyse et visualisation
â”‚   â”‚   â”‚â”€â”€ geo_scatterplot.png          # Visualisation des donnÃ©es gÃ©ographiques
â”‚   â”‚   â”‚â”€â”€ boxplots.png                 # Boxplots des donnÃ©es
â”‚   â”‚   â”‚â”€â”€ scatterplots.png             # Autres visualisations
â”‚
â”‚â”€â”€ mlflow/                              # (Optionnel) Suivi des expÃ©riences avec MLflow
â”‚
â”‚â”€â”€ venv/                                # Environnement virtuel Python
â”‚â”€â”€ .gitignore                           # Fichiers et dossiers Ã  ignorer par Git
â”‚â”€â”€ docker-compose.yml                    # Configuration Docker Compose pour l'orchestration
â”‚â”€â”€ producer.py                          # Script Kafka Producer
â”‚â”€â”€ README.md                            # Documentation du projet
```

---

##  DÃ©marrage du projet

### 1ï¸âƒ£ PrÃ©requis

- [Docker](https://www.docker.com/) et [Docker Compose](https://docs.docker.com/compose/)
- [Kafka](https://kafka.apache.org/)
- [Python 3.9+](https://www.python.org/)

### 2ï¸âƒ£ Lancer les services

git clone https://github.com/ton-repo/tp-housing-adam-saidane.git
cd tp-housing-adam-saidane


```sh

docker-compose up --build
docker ps

```


### 3ï¸âƒ£ VÃ©rifier les services

1. **Tester l'API de gestion des maisons**  
   âœ [http://127.0.0.1:5001/houses](http://127.0.0.1:5001/houses)

2. **Tester l'API de prÃ©diction**  
   âœ [http://127.0.0.1:5002](http://127.0.0.1:5002)

3. **Envoyer un message Kafka depuis le Producer**  
   ```sh
   python producer.py
   ```

4. **VÃ©rifier que le Consumer reÃ§oit les messages**  
   ```sh
   python consumer.py
   ```

---

## FonctionnalitÃ©s
## Endpoints de l'API

###  Ajouter une maison
```powershell
Invoke-RestMethod -Uri "http://127.0.0.1:5001/houses" -Method Post -Headers @{"Content-Type"="application/json"} -Body '{"longitude": -122.23, "latitude": 37.88, "housing_median_age": 52, "total_rooms": 880, "total_bedrooms": 129, "population": 322, "households": 126, "median_income": 8.3252, "median_house_value": 358500, "ocean_proximity": "NEAR BAY"}'
```
 **RÃ©ponse** : `"Maison ajoutÃ©e avec succÃ¨s !"`

###  Consommer les donnÃ©es Kafka
```powershell
docker exec -it broker kafka-console-consumer --bootstrap-server broker:9092 --topic housing_topic --from-beginning
```
 **Description** : Consomme les messages du topic Kafka `housing_topic` en affichant toutes les donnÃ©es depuis le dÃ©but.

###  VÃ©rification du fonctionnement de l'API
```powershell
Invoke-WebRequest -Uri "http://127.0.0.1:5002" -Method GET
```
 **RÃ©ponse** : `{"message": "API is running and ready to predict!"}`

###  PrÃ©diction du prix d'un logement
```powershell
Invoke-WebRequest -Uri "http://127.0.0.1:5002/predict" -Method POST -Headers @{"Content-Type"="application/json"} -Body '{"features": [-122.23, 37.88, 52, 880, 129, 322, 126, 8.3252, 358500, 1, 0, 0, 0]}'
```
 **RÃ©ponse** : `{"prediction": 443793.62}`

### ğŸ—„ RequÃªte SQL pour afficher les logements stockÃ©s
```powershell
docker exec -it housing-db psql -U housing_user -d housing -c "SELECT * FROM houses;"
```
 **Description** : Affiche toutes les maisons enregistrÃ©es dans la base de donnÃ©es PostgreSQL.

---

##  Conteneurisation avec Docker (Optionnel)

1. Construire l'image Docker :
   ```bash
   docker build -t housing-api .
   ```
2. Lancer le conteneur :
   ```bash
   docker run -p 5001:5001 housing-api
   ```

---

##  Auteurs
**Adam Saidane** - Ã‰tudiant en **Cloud Engineering** Ã  **IA Institut**.

---



